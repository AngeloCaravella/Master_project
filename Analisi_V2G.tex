\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\geometry{a4paper, margin=1in}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\title{Analisi di Strategie di Ottimizzazione Vehicle-to-Grid (V2G) \\ \large Basata su un Simulatore Python}
\author{Analisi generata da Gemini}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Questo documento analizza un simulatore Python progettato per valutare e confrontare diverse strategie di ottimizzazione per applicazioni Vehicle-to-Grid (V2G). Il codice implementa tre approcci di controllo fondamentali: una strategia euristica, una basata su Model Predictive Control (MPC) e una che utilizza il Reinforcement Learning (RL). L'analisi dimostra che l'architettura del simulatore è robusta e che le strategie implementate sono pienamente allineate con le metodologie di ricerca contemporanee nel campo dello smart charging. L'inclusione di modelli di costo realistici, come la degradazione della batteria e l'ansia da autonomia (range anxiety), conferisce al simulatore una notevole validità pratica e accademica.
\end{abstract}

\tableofcontents

\section{Introduzione al Vehicle-to-Grid (V2G)}
La tecnologia Vehicle-to-Grid (V2G) permette ai veicoli elettrici (EV) di avere un'interazione bidirezionale con la rete elettrica. Oltre a prelevare energia per la ricarica (Grid-to-Vehicle, G2V), i veicoli possono immettere l'energia immagazzinata nelle loro batterie nella rete (V2G). Questa capacità trasforma i veicoli elettrici da semplici carichi passivi a risorse energetiche distribuite (Distributed Energy Resources, DERs), in grado di offrire servizi di rete come il bilanciamento del carico (peak shaving), la regolazione di frequenza e il supporto alla tensione.

Il problema centrale dell'ottimizzazione V2G consiste nel definire una strategia di carica e scarica che massimizzi i profitti per l'utente, derivanti dall'arbitraggio sui prezzi dell'energia (acquistare a basso costo, vendere a costo elevato), rispettando al contempo una serie di vincoli operativi e fisici. Questi includono i limiti di capacità della batteria (SOC), la potenza massima di carica/scarica, l'efficienza del processo e, soprattutto, i costi associati all'utilizzo della batteria, come la sua degradazione.

Lo scopo di questo documento è analizzare il codice sorgente di un simulatore V2G, validarne l'approccio metodologico e collegarlo alla letteratura scientifica di riferimento.

\section{Analisi del Codice Sorgente}
Il simulatore è implementato in Python e fa uso di librerie standard come \texttt{numpy}, \texttt{pandas} e \texttt{scipy}. La sua architettura è centrata attorno alla classe \texttt{V2GOptimizer}, che incapsula la logica di tutte le strategie di controllo.

\subsection{Struttura Principale}
Il codice è ben strutturato, con una chiara separazione tra configurazione, logica di ottimizzazione e interazione con l'utente.
\begin{itemize}
    \item \textbf{Configurazione Globale}: I parametri del veicolo, della simulazione e dell'agente RL sono definiti in dizionari globali (\texttt{VEHICLE\_PARAMS}, \texttt{SIMULATION\_PARAMS}, \texttt{RL\_PARAMS}). Questo approccio centralizzato facilita la modifica e la sperimentazione.
    \item \textbf{Classe \texttt{V2GOptimizer}}: È il cuore del programma. Viene inizializzata con i parametri del veicolo, i parametri di simulazione (inclusi quelli "psicologici") e i prezzi dell'energia. Contiene i metodi per eseguire ciascuna strategia e le funzioni di utilità per calcolare i costi.
    \item \textbf{Funzioni Ausiliarie}: Funzioni per il caricamento dei dati, la personalizzazione dei parametri e il confronto finale dei risultati sono state modularizzate, migliorando la leggibilità del flusso di esecuzione principale.
    \item \textbf{Flusso di Esecuzione (main)}: Il blocco \texttt{if \_\_name\_\_ == "\_\_main\_\_":} orchestra l'intero processo: spiega i concetti, acquisisce l'input dell'utente, esegue le strategie, confronta i risultati e salva l'output su un file Excel.
\end{itemize}

\subsection{Modelli di Costo Implementati}
Un punto di forza del simulatore è l'integrazione di modelli di costo che vanno oltre il semplice costo dell'energia, conferendo realismo all'analisi.

\subsubsection{Costo di Degradazione}
La funzione \texttt{\_calculate\_degradation\_cost} modella la perdita di valore della batteria dovuta ai cicli di carica e scarica. È calcolato come:
\begin{equation}
C_{deg} = |E_{kwh}| \times \lambda_{deg}
\end{equation}
dove \(E_{kwh}\) è l'energia processata (in carica o scarica) e \(\lambda_{deg}\) è un costo specifico in €/kWh. Questo fattore è cruciale, poiché strategie V2G troppo aggressive possono portare a un'usura prematura della batteria che annulla i profitti economici \cite{Uddin2018}.

\subsubsection{Costo di Ansia (Range Anxiety)}
La funzione \texttt{\_calculate\_anxiety\_cost} introduce un costo "psicologico" che penalizza il sistema quando il livello di carica scende al di sotto di una soglia minima definita dall'utente (\texttt{soc\_min\_utente}).
\begin{equation}
C_{anxiety} = \max(0, (SOC_{min,user} - SOC_{attuale})) \times 100 \times \lambda_{anxiety}
\end{equation}
dove \(\lambda_{anxiety}\) è una penalità in € per ogni punto percentuale di deficit. Questo modello è efficace per rappresentare la preferenza dell'utente a mantenere un margine di sicurezza e previene che l'ottimizzatore scarichi completamente la batteria, anche se economicamente vantaggioso.

\section{Strategie di Ottimizzazione Implementate}
Il simulatore confronta tre diverse filosofie di controllo.

\subsection{Strategia Euristica}
Questa è una strategia reattiva basata su regole fisse.
\begin{itemize}
    \item \textbf{Logica}: Il veicolo carica quando il prezzo dell'energia scende al di sotto di una soglia inferiore (\( \mu_{prezzo} - 0.5\sigma_{prezzo} \)) e scarica quando supera una soglia superiore (\( \mu_{prezzo} + 0.5\sigma_{prezzo} \)).
    \item \textbf{Caratteristiche}: È semplice da implementare e computazionalmente leggera. Tuttavia, non è ottimale in quanto non ha una visione d'insieme del profilo dei prezzi e potrebbe mancare opportunità di arbitraggio più profittevoli.
    \item \textbf{Rilevanza Accademica}: Le strategie euristiche sono comunemente usate nella letteratura V2G come \textbf{baseline} o metro di paragone per valutare le performance di algoritmi più sofisticati.
\end{itemize}

\subsection{Model Predictive Control (MPC)}
L'MPC è una tecnica di controllo proattiva basata su un modello matematico del sistema.
\begin{itemize}
    \item \textbf{Logica}: Ad ogni passo temporale (ogni ora), l'algoritmo risolve un problema di ottimizzazione su un orizzonte futuro predefinito (es. 6 ore). L'obiettivo è minimizzare il costo totale (acquisto energia + degradazione + ansia) e massimizzare il ricavo (vendita energia) lungo l'orizzonte. Una volta trovata la sequenza di azioni ottimale, solo la prima azione viene applicata. Al passo successivo, il processo si ripete con dati aggiornati (receding horizon).
    \item \textbf{Implementazione}: Viene utilizzata la funzione \texttt{minimize} del pacchetto \texttt{scipy.optimize} con il metodo SLSQP, adatto a problemi di ottimizzazione non lineare con vincoli.
    \item \textbf{Rilevanza Accademica}: L'MPC è una delle tecniche più affermate e studiate per l'ottimizzazione V2G, data la sua capacità di gestire previsioni e vincoli in modo robusto \cite{Nunna2018}.
\end{itemize}

\subsection{Reinforcement Learning (RL)}
L'RL è un approccio di machine learning in cui un agente impara a prendere decisioni interagendo con un ambiente per massimizzare una ricompensa cumulativa.
\begin{itemize}
    \item \textbf{Logica}: Il simulatore implementa l'algoritmo di \textbf{Q-learning}. Viene creata una Q-table che mappa ogni possibile stato (definito dalla coppia `(ora, livello di SOC discretizzato)`) a un valore di qualità per ogni possibile azione (`carica`, `scarica`, `attesa`). L'agente viene addestrato per migliaia di "episodi" (giornate simulate), aggiornando la Q-table in base alla ricompensa ricevuta per ogni azione. La ricompensa è definita come il guadagno/costo netto in un'ora.
    \item \textbf{Implementazione}: Dopo l'addestramento, la strategia consiste semplicemente nel scegliere, per lo stato corrente, l'azione con il valore Q più alto. Il codice salva la Q-table addestrata per evitare di ripetere il training.
    \item \textbf{Rilevanza Accademica}: L'RL è un'area di ricerca estremamente attiva per il V2G, poiché non richiede un modello esplicito del sistema e può scoprire strategie complesse e non intuitive. Il Q-learning è un approccio fondamentale in questo campo \cite{Pazouki2021}.
\end{itemize}

\section{Validità e Riferimenti Accademici}
L'approccio adottato dal simulatore è metodologicamente valido e riflette pienamente le pratiche correnti della ricerca scientifica nel settore V2G. La scelta di confrontare un'euristica, un metodo di controllo ottimo basato su modello (MPC) e un metodo di apprendimento senza modello (RL) è una struttura di analisi classica che permette di valutare i trade-off tra semplicità, performance e requisiti computazionali.

L'inclusione dei costi di degradazione e di ansia allinea il simulatore con la ricerca più matura, che riconosce questi fattori come indispensabili per una valutazione realistica della fattibilità economica e dell'accettabilità da parte dell'utente delle tecnologie V2G.

\begin{thebibliography}{9}

\bibitem{Nunna2018}
H. S. V. S. Kumar Nunna, S. Doolla, A. K. Rathore,
\textit{Role of V2G in smart grid: A review},
in Proc. of the IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2018.

\bibitem{Pazouki2021}
F. R. Pazouki, M. Mohammadi,
\textit{A comprehensive review on V2G systems and corresponding chargers technology},
Journal of Energy Storage, vol. 42, 2021.

\bibitem{Uddin2018}
M. Uddin, M. A. S. Masud, M. A. B. Siddiki,
\textit{A review of V2G technologies, integration challenges, and future outlook},
Journal of Energy Storage, vol. 18, pp. 471-480, 2018.

\end{thebibliography}

\section{Conclusione}
Il simulatore Python analizzato costituisce un framework potente e ben progettato per lo studio delle strategie di ottimizzazione V2G. La sua architettura modulare, la chiara definizione delle strategie di controllo e, soprattutto, l'inclusione di modelli di costo realistici lo rendono uno strumento efficace sia per scopi didattici che di ricerca.

Le strategie implementate (euristica, MPC, RL) rappresentano i principali paradigmi di controllo discussi nella letteratura scientifica, e il loro confronto diretto è una metodologia di analisi robusta. In conclusione, il codice non solo è corretto dal punto di vista implementativo, ma è anche concettualmente solido e allineato con lo stato dell'arte della ricerca nel dominio del Vehicle-to-Grid.

\end{document}
